type SpeechRecognitionEvent = Event & {
  resultIndex: number;
  results: SpeechRecognitionResultList;
};

interface SpeechRecognitionInstance {
  lang: string;
  continuous: boolean;
  interimResults: boolean;
  start: () => void;
  stop: () => void;
  onstart: (() => void) | null;
  onend: (() => void) | null;
  onerror: ((event: { error: string }) => void) | null;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
}

type SpeechRecognitionConstructor = new () => SpeechRecognitionInstance;

const startBtn = document.getElementById("recordStartBtn") as HTMLButtonElement | null;
const stopBtn = document.getElementById("recordStopBtn") as HTMLButtonElement | null;

const subtitleEl = document.getElementById("subtitle") as HTMLDivElement | null;
const SpeechRecognitionClass =
  (window as Window &
    typeof globalThis & {
      SpeechRecognition?: SpeechRecognitionConstructor;
      webkitSpeechRecognition?: SpeechRecognitionConstructor;
    }).SpeechRecognition ||
  (window as Window &
    typeof globalThis & {
      SpeechRecognition?: SpeechRecognitionConstructor;
      webkitSpeechRecognition?: SpeechRecognitionConstructor;
    }).webkitSpeechRecognition;

if (!SpeechRecognitionClass) {
  console.error("Web Speech APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.");
} else {
  const recognition = new SpeechRecognitionClass();
  recognition.lang = "ko-KR";
  recognition.continuous = true;
  recognition.interimResults = true;

  let isRecording = false;
  let finalTranscript = ""; 

  const updateSubtitle = (text: string) => {
    if (subtitleEl) {
      subtitleEl.innerText = text.trim() || "ì¸ì‹ëœ ë¬¸ì¥ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.";
    }
  };

  recognition.onstart = () => {
    console.log("ğŸ¤ onstart: ìŒì„± ì¸ì‹ ì‹œì‘");
    updateSubtitle("ìŒì„±ì„ ë“£ëŠ” ì¤‘...");
  };

  recognition.onend = () => {
    console.log("ğŸ›‘ onend: ìŒì„± ì¸ì‹ ì¢…ë£Œ");
    console.log("âœ… ìµœì¢… ì¸ì‹ ê²°ê³¼:", finalTranscript.trim());
    updateSubtitle(finalTranscript || "ì¸ì‹ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");

    finalTranscript = "";
    isRecording = false;
  };

  recognition.onerror = (e: { error: string }) => {
    console.error("âŒ onerror:", e.error);
    isRecording = false;
  };

  recognition.onresult = (event: SpeechRecognitionEvent) => {
    // ìƒˆë¡œ ì¸ì‹ëœ ê²°ê³¼ë“¤ë§Œ ì²˜ë¦¬
    for (let i = event.resultIndex; i < event.results.length; i++) {
      const result = event.results[i];
      const text = result[0].transcript;

      if (result.isFinal) {
        finalTranscript += text + " ";
        updateSubtitle(finalTranscript);
      }

      // console.log(result.isFinal ? "ğŸ‘‰ í™•ì •ëœ ë¬¸ì¥:" : "â³ ì¤‘ê°„ ì¸ì‹:", text);
    }
  };

  startBtn?.addEventListener("click", () => {
    console.log("â–¶ start ë²„íŠ¼ í´ë¦­, isRecording =", isRecording);
    if (isRecording) return;

    try {
      isRecording = true;
      finalTranscript = ""; // ìƒˆ ë…¹ìŒ ì‹œì‘ ì‹œ ì´ˆê¸°í™”
      recognition.start();
      console.log("ğŸ¬ recognition.start() í˜¸ì¶œ");
    } catch (err: any) {
      console.log("start ì¤‘ë³µ í˜¸ì¶œ ì˜ˆì™¸:", err?.message);
      isRecording = false;
    }
  });

  stopBtn?.addEventListener("click", () => {
    console.log("â›” stop ë²„íŠ¼ í´ë¦­, isRecording =", isRecording);
    if (!isRecording) return;

    try {
   
      recognition.stop();
      console.log("ğŸ›‘ stop() í˜¸ì¶œ (ì¸ì‹ ë§ˆë¬´ë¦¬ í›„ onend í˜¸ì¶œë  ê²ƒ)");
      updateSubtitle(finalTranscript || "ì¸ì‹ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...");
 
    } catch (err: any) {
      console.log("stop ì˜ˆì™¸:", err?.message);
    }
  });
}
